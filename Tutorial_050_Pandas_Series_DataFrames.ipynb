{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial 05, Part 0: Pandas, series, data frames \n",
    "[The official project homepage](https://pandas.pydata.org)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic data structures - start with Series then build up to DataFrames\n",
    "\n",
    "[Pandas quick start guide for Series](https://pandas.pydata.org/pandas-docs/stable/dsintro.html#series)\n",
    "\n",
    "* A **Series** is a 1D array that can hold any type of data (numeric types, non-numeric, Python objects and so forth).\n",
    "    * Unlike a 1D numpy array, each entry is **labeled** with an index that is used to keep track of what each entry is, and can be used to lookup the value corresponding to each index during analysis.\n",
    "    * These labels are fixed - they will always index the same value unless you explicitly break that link.\n",
    "    * The list of labels that forms the index can either be declared upon series creation or, by default, it will range from 0 to len(data)-1.\n",
    "        * If you're going to use Pandas to organize your data, specifying usable and informative labels is a good idea because that's one of the main advantages of organizing your data in this manner - if you just want to fly blind then NumPy is usually fine on its own\n",
    "        \n",
    "<div class=\"alert alert-warning\">\n",
    "Pandas will allow you to specify non-unique labels. This can be ok for operations that don't rely on indexing by label. However, operations that do rely on unique labels for indexing may throw an unexpected error so in general its good practice to use unique labels!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard numpy and matplotlib imports\n",
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "\n",
    "# for plotting in a separte window (not inline with notebook output)\n",
    "# %matplotlib qt\n",
    "\n",
    "# import a generic pandas object and also a few specific functions that we'll use\n",
    "import pandas as pd \n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "# new - get and store current file path for file i/o later on in tutorial\n",
    "import os\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# also define the default font we'll use for figures. \n",
    "fig_font = {'fontname':'Arial', 'size':'20'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a series from an numpy ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index labels:  ['Sub0', 'Sub1', 'Sub2', 'Sub3', 'Sub4', 'Sub5', 'Sub6', 'Sub7', 'Sub8', 'Sub9', 'Sub10', 'Sub11'] \n",
      "\n",
      "Sub0     0.699258\n",
      "Sub1     1.274437\n",
      "Sub2     1.780352\n",
      "Sub3     0.201680\n",
      "Sub4     0.804139\n",
      "Sub5     1.835721\n",
      "Sub6     0.493615\n",
      "Sub7     1.047985\n",
      "Sub8     1.871220\n",
      "Sub9     2.090627\n",
      "Sub10    1.343622\n",
      "Sub11    1.080105\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# make some data and then use pd.Series\n",
    "\n",
    "# random seed so we get the same thing each time \n",
    "np.random.RandomState(0)\n",
    "\n",
    "# For this simulation, lets have 20 subjects, and some data\n",
    "# generated from a Rayleigh distribution \n",
    "# (no particular motivation for selecting this distribution, just for something different)\n",
    "# Rayleigh is the distribution of vector magnitudes generated by two independent components (e.g. wind speed)\n",
    "N = 12\n",
    "data = np.random.rayleigh(scale=1, size=N)\n",
    "\n",
    "# make a list of subject names for use as an index labels\n",
    "label_prefix = 'Sub'\n",
    "index=[]\n",
    "for n in np.arange(N):\n",
    "    index.append(label_prefix+str(n))\n",
    "\n",
    "print('Index labels: ', index, '\\n')\n",
    "\n",
    "# then make our pandas series by passing in our data array and our index labels\n",
    "s = pd.Series(data, index=index)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note that each subject is now a field in the series and can be used to retrieve the corresponding value...there are a few ways to do this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# access by field\n",
    "print(s.Sub11)\n",
    "\n",
    "# access by index label (like a dictionary)\n",
    "print(s['Sub11'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can also use labels to check for membership or to index over labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for membership\n",
    "'Sub11' in s\n",
    "\n",
    "# iterate over index labels, with l==index name\n",
    "for l in s.index:\n",
    "    print(l)\n",
    "\n",
    "# iterate over data in series\n",
    "for d in s:\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Before moving on, there are a few other optional (but important) parameters of the pd.Series call\n",
    "* dtype - default is to infer the data type (int32, float64, str, etc) based on the values in data\n",
    "    * However, can also explicitly declare the data\n",
    "    * This can be good if you want to, for example, re-cast the data to save space or to make types compatible\n",
    "    * But this may also have important negative consequences if not done thoughtfully! \n",
    "* copy - if not specified then the default behavior is set to False and the new series will have a 'view' of the data.\n",
    "    * This can save space, but can sometimes lead to confusion as any change to the values in s will also change the values in the original 'data' array\n",
    "    * Setting copy=False will make a new copy of the data in 's' that is independent of the input 'data' array\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explicitly declare a different dtype to see where things can go wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a series with the data array from above, but make it int32 instead of the inferred (and correct) float64 type\n",
    "s = pd.Series(data, index=index, dtype='int32')\n",
    "\n",
    "# first 4 values in our original data array\n",
    "print(data[:4])\n",
    "\n",
    "# first 4 values in our series of type int32...might not be what you want!\n",
    "print('\\n', s[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example: declaring dtype can be handy if you want to, for example, do str manipulations with the data array or if you want to merge with another series of type str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a series with the data array from above, but this time make it a str\n",
    "# instead of the inferred float64 type\n",
    "s = pd.Series(data, index=index, dtype='str')\n",
    "\n",
    "# first 4 values in our original data array\n",
    "print(data[:4])\n",
    "\n",
    "# first 4 values in our series of type str...preserves info and we're now\n",
    "# all set to do a bunch of str operation without having to deal with \n",
    "# explictly recasting each time we interact with the values in s\n",
    "print('\\n', s[:4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note that the dtype of series 's' is now an 'object'. This is the Pandas equivalent of a Python 'str'\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now explicitly ask for a 'view' of the data instead of the default copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:  [0 1 2 3] \n",
      "\n",
      "Original values in series\n",
      "d1    0\n",
      "d2    1\n",
      "d3    2\n",
      "d4    3\n",
      "dtype: int32\n",
      "\n",
      "New values in series\n",
      "d1    100\n",
      "d2      1\n",
      "d3      2\n",
      "d4      3\n",
      "dtype: int32\n",
      "\n",
      "New data: [100   1   2   3] \n",
      "data[0] changed too!\n"
     ]
    }
   ],
   "source": [
    "# same as before - create a series based on a short data array (0:4 in this case for simplicity)\n",
    "# let Pandas figure out the dtype, and use the default copy behavior (i.e. copy=False)\n",
    "\n",
    "N = 4                # number of data points\n",
    "\n",
    "# make data\n",
    "data = np.arange(N)\n",
    "# make index labels\n",
    "index = ['d1','d2','d3','d4']\n",
    "\n",
    "# print out the original data array for reference\n",
    "print('Original data: ', data, '\\n')\n",
    "\n",
    "# make a series with the default behavior of copy=False\n",
    "s = pd.Series(data, index=index, copy=False)\n",
    "\n",
    "# print out the new series\n",
    "print('Original values in series')\n",
    "print(s)\n",
    "\n",
    "# now change the value of the first entry in the series\n",
    "s['d1'] = 100\n",
    "\n",
    "# new values in series 's'\n",
    "print('\\nNew values in series')\n",
    "print(s)\n",
    "\n",
    "# and then print the corresponding entry in the data array\n",
    "print('\\nNew data:', data, '\\ndata[0] changed too!')\n",
    "\n",
    "# Note that data[0] changed because the values in s are a view of data...\n",
    "# both are referencing the same chunk of memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-danger\">\n",
    "Note that this works in the other direction too, which can be more insidious...if you create a Series based on the values in 'data', and then do more work with 'data', then every time you change a value in the original data array, you will also change the corresponding value in s!!!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data:  [0 1 2 3] \n",
      "\n",
      "Original values in series\n",
      "d1    0\n",
      "d2    1\n",
      "d3    2\n",
      "d4    3\n",
      "dtype: int32\n",
      "\n",
      "New values in series\n",
      "d1    100\n",
      "d2      1\n",
      "d3      2\n",
      "d4      3\n",
      "dtype: int32\n",
      "\n",
      "New data is the same as the old data: [0 1 2 3]\n",
      "data[0] did not change because it is independent from values in s\n"
     ]
    }
   ],
   "source": [
    "# now do the same thing but this time lets explicitly ask for a copy of the data\n",
    "N = 4                # number of data points\n",
    "\n",
    "# make data\n",
    "data = np.arange(N)\n",
    "# make index labels\n",
    "index = ['d1','d2','d3','d4']\n",
    "\n",
    "# print out the original data array for reference\n",
    "print('Original data: ', data, '\\n')\n",
    "\n",
    "# make a series, but change the default behavior of copy to copy=True\n",
    "s = pd.Series(data, index=index, copy=True)\n",
    "\n",
    "# print out the new series\n",
    "print('Original values in series')\n",
    "print(s)\n",
    "\n",
    "# now change the value of the first entry in the series\n",
    "s['d1'] = 100\n",
    "\n",
    "# new values in series 's'\n",
    "print('\\nNew values in series')\n",
    "print(s)\n",
    "\n",
    "# and then print the corresponding entry in the data array\n",
    "print('\\nNew data is the same as the old data:', data)\n",
    "print('data[0] did not change because it is independent from values in s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## After creating a pandas series, you can do many common operations and access the functionality of other modules \n",
    "* A pd Series behaves similar to a NumPy ndarray, and can be passed to many NumPy functions\n",
    "* Slicing also works like a ndarray - note that index is also sliced\n",
    "* Lots of built in methods as well that emulate NumPy functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can pass pd.Series to most NumPy functions... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean:  1.16039477001477 Max:  3.25989519135\n"
     ]
    }
   ],
   "source": [
    "# make a new series...\n",
    "N = 16\n",
    "data = np.random.exponential(size=N)\n",
    "\n",
    "# make some labels\n",
    "label_prefix = 'Exp'\n",
    "index=[]\n",
    "for n in np.arange(N):\n",
    "    index.append(label_prefix+str(n))\n",
    "    \n",
    "# make the series\n",
    "s = pd.Series(data, index=index)\n",
    "print('\\nMean: ', np.mean(s), 'Max: ', np.max(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Note that the index labels come along for the ride "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exp0     0.922508\n",
      "Exp1     3.259895\n",
      "Exp2     0.271713\n",
      "Exp3     1.029167\n",
      "Exp4     0.616481\n",
      "Exp5     2.044292\n",
      "Exp6     0.467407\n",
      "Exp7     2.982640\n",
      "Exp8     0.379235\n",
      "Exp9     0.319465\n",
      "Exp10    1.292761\n",
      "Exp11    0.036772\n",
      "Exp12    0.979448\n",
      "Exp13    2.557037\n",
      "Exp14    1.111187\n",
      "Exp15    0.296307\n",
      "dtype: float64\n",
      "\n",
      "Cumproduct\n",
      "\n",
      "Exp0     0.922508\n",
      "Exp1     3.007281\n",
      "Exp2     0.817117\n",
      "Exp3     0.840950\n",
      "Exp4     0.518430\n",
      "Exp5     1.059822\n",
      "Exp6     0.495368\n",
      "Exp7     1.477506\n",
      "Exp8     0.560321\n",
      "Exp9     0.179003\n",
      "Exp10    0.231408\n",
      "Exp11    0.008509\n",
      "Exp12    0.008334\n",
      "Exp13    0.021311\n",
      "Exp14    0.023681\n",
      "Exp15    0.007017\n",
      "dtype: float64\n",
      "None\n",
      "0.231408434073\n",
      "0.231408434073\n"
     ]
    }
   ],
   "source": [
    "# print our series - set of index labels along with data values\n",
    "print(s)\n",
    "\n",
    "# then apply the NumPy cumulative product operation (multiply N with N+1, then that result by N+2, etc)\n",
    "cp = np.cumprod(s)\n",
    "\n",
    "print('\\nCumproduct\\n')\n",
    "print(print(cp))\n",
    "\n",
    "# cool part: note that the output also contains the label info, which is handy to keep track of things!\n",
    "# and you can index into cp using the index labels\n",
    "print(cp['Exp10'])\n",
    "print(cp.Exp10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.exponential(N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "d1    100\n",
      "d2      1\n",
      "d3      2\n",
      "d4      3\n",
      "dtype: int32\n"
     ]
    }
   ],
   "source": [
    "# Grab specific values (3rd entry here)\n",
    "print(s[2])\n",
    "\n",
    "# find all entries where data > .9\n",
    "print(s[s>.9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More advanced slicing - note that index labels come along for the ride \n",
    "s[:-1]    #0:end-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Series have many built in operations, much like NumPy \n",
    "[list of attributes and methods](https://pandas.pydata.org/pandas-docs/version/0.23.4/generated/pandas.Series.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# attributes\n",
    "print('Data Type: ', s.dtype)\n",
    "\n",
    "# basic methods\n",
    "print('Mean: ', s.mean(), ' Std:', s.std(), 'Max: ', s.max())\n",
    "\n",
    "# numerical derivative\n",
    "print('Diff: ', s.diff())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can also make series from scalars (assign all indices same value) or from dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Suppose you want a series with all the same values...you can do this using np.repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N=4\n",
    "data = np.repeat(14, N)\n",
    "index = np.arange(N) \n",
    "\n",
    "# make the series\n",
    "s = pd.Series(data, index=index)\n",
    "\n",
    "# all entries will have the same value\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can achieve the same thing like this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# series from scalars\n",
    "N=4\n",
    "\n",
    "# don't need repeat cause its a single scalar linked to each index\n",
    "data = 14\n",
    "index = np.arange(N) \n",
    "\n",
    "# make the series\n",
    "s = pd.Series(data, index=index)\n",
    "\n",
    "# all entries will have the same value\n",
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Can also initialize with a dict (keys become index, values become data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = {'Bob' : 20, 'Ella' : 17, 'Sam' : 23, 'Jack' : 25.3}\n",
    "s = pd.Series(data)\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "Note that data type is upcast to highest precision entry\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrames\n",
    "\n",
    "* \n",
    "* \n",
    "* \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a data set that we can play with, will import some real data later on\n",
    "* just make up some stuff here...lets say responses in 5 different neurons to different stimuli "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed random number generator\n",
    "np.random.RandomState(0)\n",
    "\n",
    "# dependent variables - 5 neurons...\n",
    "neurons = ['Nrn1','Nrn2','Nrn3','Nrn4','Nrn5','Nrn6','Nrn7','Nrn8','Nrn9','Nrn10']  \n",
    "\n",
    "# independent variables...responses in Hz to two stimulus conditions\n",
    "resp1_hz = [14, 27, 62, 88, 45, 56, 75, 63, 33, 46]\n",
    "\n",
    "# set up our response to stimulus 2...use random.randint for fun\n",
    "min_resp = 1  # inclusive\n",
    "max_resp = 90 # exclusive\n",
    "resp2_hz = np.random.randint(1, 90, len(resp1_hz))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New - use 'zip' function to wrap up the data from each list into one list\n",
    "* does like it sounds like it does - takes three iterators and groups them together into a single iterator with the 1st element in each iterator together, then the second, etc. \n",
    "* length of resulting iterator limited by the length of the shortest input iterator\n",
    "\n",
    "[reference](https://www.w3schools.com/python/ref_func_zip.asp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neuron_data = list(zip(neurons, resp1_hz, resp2_hz))\n",
    "print(neuron_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a dataframe object to hold the contents of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data = neuron_data, columns = ['neuron', 'resp1', 'resp2'])\n",
    "\n",
    "# take a look at the nice output here...\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving data in a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # lets save our header as well so that it doesn't think our first row is the header when we read the file back in\n",
    "df.to_csv('spike_rates.csv',index=False,header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use our current working directory to build a path to the file\n",
    "print(cwd)\n",
    "file_name = cwd + '/spike_rates.csv'\n",
    "print(file_name)\n",
    "\n",
    "df = pd.read_csv(file_name)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get a high-level summary of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Can also apply a set of more targeted analyses using the df object\n",
    "\n",
    "* [Pandas doc for all functions](https://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making cooler DataFrame styles (and more useful...although that should take a backseat to coolness)\n",
    "[Check here for a bunch of neat style options](https://pandas.pydata.org/pandas-docs/stable/style.html)\n",
    "* Simple demo - can write custom functions that highlight specific aspects of your data - can be very useful for more clearly highlighting/communicating key points in the data within a notebook  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_max(s):\n",
    "    '''\n",
    "    highlight the maximum in a Series yellow.\n",
    "    '''\n",
    "    is_max = s == s.max()\n",
    "    return ['background-color: yellow' if v else '' for v in is_max]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
